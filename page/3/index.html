<html>
  <head>
	<meta name="generator" content="Hugo 0.54.0" />
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-155190626-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-155190626-1');
    </script>
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css"></link>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/skeleton/2.0.4/skeleton.css"></link>
    <link href="https://fonts.googleapis.com/css?family=Lato|M+PLUS+1p|M+PLUS+Rounded+1c|Roboto&display=swap" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="/css/base.css"></link>
    
  <link rel="stylesheet" type="text/css" href="/css/index.css"></link>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body class="container">
    <header>
      <h1><a href="/">Coda</a></h1>
      <nav>
	<ul>
	  <li><a href="/posts/">Posts</a></li>
	  <li><a href="/about/">About</a></li>
	</ul>
      </nav>
    </header>
    <main>
      
  
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/squad/">論文メモ SQuAD: 100,000&#43; Questions for Machine Comprehension of Text</a></h2>
	  <p>August 28, 2020</p>
	</header>
	<div class="excerpt"><p>読解タスクのテストデータセットSQuADをつくり、ロジスティック回帰で難易度を評価した。
難易度は、ベースラインのF1スコアが20%, 強いモデルで51.0%, 人間で86.8%程度である。</p></div>
	<a class="readmore" href="/posts/squad/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/extensible_effects/">論文メモ Extensible Effects An Alternative to Monad Transformers</a></h2>
	  <p>August 23, 2020</p>
	</header>
	<div class="excerpt"><p>モナド変換子にかわるモナドの合成方法Extensible Effectsの実装を示す。</p></div>
	<a class="readmore" href="/posts/extensible_effects/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/when_and_why_your_code_starts_to_smell_bad/">論文メモ When and Why Your Code Starts to Smell Bad</a></h2>
	  <p>August 21, 2020</p>
	</header>
	<div class="excerpt"><p>200件のAndroid, Apache, EclipseのOSSプロジェクトのコミット履歴を調査し、不吉な匂いが生じる原因と理由を調査した。
常識では、改修の繰返しによって匂いのない既存のコードに匂いが生じると考えられているが、これに反して、不吉な匂いのするコードのほとんどが作成時点で不吉な匂いを出していたことを明らかにした。</p></div>
	<a class="readmore" href="/posts/when_and_why_your_code_starts_to_smell_bad/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/extracting_and_composing_robust_features_with_denoising_autoencoders/">論文メモ Extracting and Composing Robust Features with Denoising Autoencoders</a></h2>
	  <p>August 21, 2020</p>
	</header>
	<div class="excerpt"><p>ノイズを含む入力からノイズのない入力を復元するように学習すると、次元圧縮の性能を向上できることを示した。
層の深いautoencoderを学習するには、良い初期値を与えなければらないことが知られていた。
<a href="https://www.cs.toronto.edu/~hinton/science.pdf">先行研究</a>は、各中間層を個別に学習することで、良い初期値を求められることを示した。
具体的には、各中間層について、前の層の入力から次の層の出力を推定できるよう個別に学習させる。
一方で、何が良い初期値をなすのかは知られていなかった。
表題の論文は、その条件は入力に含まれるノイズに対して頑強であると仮説をおき、ノイズを除去できるように目的関数を設定することで、次元圧縮の性能が上がることを示し、仮説の正しさを確かめた。</p></div>
	<a class="readmore" href="/posts/extracting_and_composing_robust_features_with_denoising_autoencoders/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/statistical_errors_in_software_engineering_experiments/">論文メモ Statistical Errors in Software Engineering Experiments: A Preliminary Literature Review</a></h2>
	  <p>August 14, 2020</p>
	</header>
	<div class="excerpt"><p>ソフトウェア工学の実験において、統計をもちいた手法がどれだけ誤用されているかを調査した。
薬学や心理学の実験では、統計による手法が時に誤って使われていることが知られている。
一方で、ソフトウェア工学では、どの程度誤用がみられるのかは分かっていない。
著者らは、2006から2015年のソフトウェア工学のトップ会議ICSEで発表された論文770件から、実験や評価に統計的手法をもちいたものを選び、10の観点からなる判断基準で、手法の妥当性を評価した。</p></div>
	<a class="readmore" href="/posts/statistical_errors_in_software_engineering_experiments/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/semi-supervised_learning_with_ladder_networks/">論文メモ Semi Supervised Learning with Ladder Networks</a></h2>
	  <p>August 14, 2020</p>
	</header>
	<div class="excerpt"><p>Ladder Networkを半教師あり学習に応用する。
Ladder Networkは、2015年に、著者の一人Valpolaによって教師なし学習のためのネットワークとして発表されている<a href="https://arxiv.org/abs/1411.7783">*</a>。</p></div>
	<a class="readmore" href="/posts/semi-supervised_learning_with_ladder_networks/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/an_empirical_study_on_program_failures_on_deep_learning_jobs/">論文メモ An Empirical Study On Program Failures On Deep Learning Jobs</a></h2>
	  <p>August 7, 2020</p>
	</header>
	<div class="excerpt"><p>Microsoftの社内では深層学習のプラットフォームPhillyが運用されており、そこで起きた4960件のジョブの失敗原因を調査した。
調査では、失敗の原因を20のカテゴリに分類し、カテゴリごとに失敗の件数を集計した。</p></div>
	<a class="readmore" href="/posts/an_empirical_study_on_program_failures_on_deep_learning_jobs/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/improving_language_understanding_by_generative_pre_training/">論文メモ Improving Language Understanding by Generative Pre-Training</a></h2>
	  <p>August 7, 2020</p>
	</header>
	<div class="excerpt"><h3 id="概要">概要</h3>

<p>GPTの略称で知られる教師なしの事前学習である。
評価実験では、12の自然言語処理タスクのうち9つで、当時のSoTAを上まわる性能を発揮した。
ネットワークはTransformerであり、事前学習では言語モデルを学習する。
手法の独自性は、ファインチューニングでの入力データの作り方にある。
入力形式を工夫し、事前学習時のネットワーク構成を維持することで、効率的な転移学習を実現する。</p></div>
	<a class="readmore" href="/posts/improving_language_understanding_by_generative_pre_training/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/a_tale_from_the_trenches/">論文メモ A Tale from the Trenches: Cognitive Biases and Software Development</a></h2>
	  <p>July 31, 2020</p>
	</header>
	<div class="excerpt"><p>エンジニア10人の普段の開発状況から、認知バイアスが開発者にあたえる影響やバイアスの頻度、対策方法について調査した。</p></div>
	<a class="readmore" href="/posts/a_tale_from_the_trenches/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/factorization_machines/">論文メモ Factorization Machines</a></h2>
	  <p>July 31, 2020</p>
	</header>
	<div class="excerpt"><p>Factorization Machineは、Matrix factorizationのようなFactorization modelとSVMの両方の利点をもつ。
Matrix modelには疎な特徴を入力することができるが、予測のモデルに使うには汎用性に欠ける。
一方、SVMは、汎用的であるが、推薦システムで使われるような疎な特徴を扱うことができない。
Factorizatiom Machineは、両者の利点をそなえており、疎な任意の実数を要素にもつ特徴ベクトルを扱うことができる。
また、予測の計算量が線形であり、必要なパラメタの数も線形であるため、SVMのサポートベクタのように訓練データをモデルに持たせる必要がない。
そのために、大量の訓練データを使う学習も可能となる。</p></div>
	<a class="readmore" href="/posts/factorization_machines/">Read more</a>
      </article>
    
  
  <div class="pagination">
  
    <a href="/"><i class="material-icons">first_page</i></a>
  
  
    <a href="/page/2/"><i class="material-icons">chevron_left</i></a>
  
  
    <a href="/page/4/"><i class="material-icons">chevron_right</i></a>
  
  
    <a href="/page/12/"><i class="material-icons">last_page</i></a>
  
</div>


    </main>
    <footer>
      <ul>
       
       <li>
	 <a href="https://github.com/nryotaro"><i class="fab fa-github"></i></a>
       </li>
       
       
       <li>
	 <a href="https://www.linkedin.com/in/nakamura-ryotaro">
	   <i class="fab fa-linkedin"></i>
	 </a>
       
       </li>
	<li><a href="/index.xml"><i class="fas fa-rss"></i></a></li>
      </ul>
      <small>&copy; Nakamura, Ryotaro. All Rights Reserved.</small>
    </footer>
  </body>
</html>
