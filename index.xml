<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Coda</title>
    <link>https://nryotaro.github.io/</link>
    <description>Recent content on Coda</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 10 Aug 2019 14:39:11 +0900</lastBuildDate>
    
	<atom:link href="https://nryotaro.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>メモ Are We Really Making Much Progress? A Worring Analysis of Recent Neural Recomendation Approaches</title>
      <link>https://nryotaro.github.io/post/are_we_really_making_much_progress/</link>
      <pubDate>Sat, 10 Aug 2019 14:39:11 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/are_we_really_making_much_progress/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題は、ニューラルネットワークを用いた推薦システムを提案、評価した論文における実験の再現性と予測性能の再評価した論文のタイトルにあたる。
発表学会は、2019年のRecSys。著者らは、以下の2つのRQに回答するためにトップ会議で発表された18の論文を調査した。その結果、実験を再現できた論文は7稿であり、その中でも単純な手法を上回る性能が認められたのは1稿だけだった。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RQ1: ニューラルネットワークを用いた推薦システムの研究の再現性はどの程度か&lt;/li&gt;
&lt;li&gt;RQ2: 最近発表されたアルゴリズムは、ハイパーパラメタチューニングされた単純な手法と比べてどの程度性能がいいか&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>メモ Gaussian Processes for Regression</title>
      <link>https://nryotaro.github.io/post/gaussian_processes_for_regression/</link>
      <pubDate>Sat, 03 Aug 2019 21:54:03 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/gaussian_processes_for_regression/</guid>
      <description>&lt;p&gt;表題はガウス過程の回帰問題への応用を提案した論文。著者らは、scikit-learnの&lt;a href=&#34;https://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process&#34;&gt;ガウス過程回帰&lt;/a&gt;の
元になっている&lt;a href=&#34;http://www.gaussianprocess.org/gpml/chapters/RW.pdf&#34;&gt;Gaussian Processes for Machine Learning&lt;/a&gt;の著者と同じ。
論文の構成は、ガウス過程回帰の予測分布の式、ハイパーパラメタ推定方法、実験による評価からなる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Google Vizier: A Service for Black-Box Optimization</title>
      <link>https://nryotaro.github.io/post/google_vizier/</link>
      <pubDate>Sat, 03 Aug 2019 17:18:36 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/google_vizier/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にあるVizierはGoogleにおいてデファクトになっているブラックボックス最適化のためのサービスであり、
論文は、Vizierのシステムアーキテクチャの構成とアルゴリズムの説明とその評価からなる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Learning Active Learning from Data</title>
      <link>https://nryotaro.github.io/post/learning_active_learning_from_data/</link>
      <pubDate>Sat, 27 Jul 2019 16:40:43 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/learning_active_learning_from_data/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にある論文は、次にラベルを与えるべきデータが何かという能動学習における問題を、
あるサンプルを教師データに追加したときの損失関数の減少値を予測する回帰の問題としてとらえる。
能動学習の目的は最小限データで最大の予測性能をもつモデルを構築することであり、次にアノテーションすべきデータが何かを正しく予測することが課題になる。
論文は、アノテーションすべきサンプルを予測する回帰モデルを学習するアルゴリズムを提案、評価する。アルゴリズムは2値分類の分類器を対象としている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 TextRank: Bringing Order into Texts</title>
      <link>https://nryotaro.github.io/post/textrank/</link>
      <pubDate>Sat, 20 Jul 2019 17:49:36 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/textrank/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にある論文は、ドキュメントからキーワードとキーセンテンスを抽出するためのグラフベースのアルゴリズムTextRankを提案、評価した。
TextRankは、名前から推測できるようにPageRankを応用した手法であり、頂点の重要度を、頂点の内容のような局所的な情報ではなく、他の頂点との辺の接続関係を含むグラフ全体の大域的な情報から決定する。PageRankとTextRankのアルゴリズムの違いは、TextRankの場合は辺ごとに重みが設定できるところにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates</title>
      <link>https://nryotaro.github.io/post/subword_regularization/</link>
      <pubDate>Wed, 17 Jul 2019 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/subword_regularization/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題は、過去に&lt;a href=&#34;../neural_machine_translation_of_rate_words/&#34;&gt;紹介&lt;/a&gt;した&lt;a href=&#34;https://www.aclweb.org/anthology/P16-1162&#34;&gt;論文&lt;/a&gt;と同様、sentencepiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）の元になった論文にあたる。
ノイズに対する頑強さのために、単語のサブワード（部分文字列）を生成するユニグラム言語モデルの学習方法と、モデルから生成されたサブワード列を入力とする機械翻訳モデルの学習方法を提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Neural Machine Trasnslation of Rare Words with Subword Units</title>
      <link>https://nryotaro.github.io/post/neural_machine_translation_of_rate_words/</link>
      <pubDate>Sat, 13 Jul 2019 17:19:10 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/neural_machine_translation_of_rate_words/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;内容は、sentencepiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）のトークナイズで使われるアルゴリズムになっている。単語をサブワード（単語の部分文字列）に分割し、サブワードを組み合わせて珍しい単語や未知語を表現することで、これらの出現頻度の低い単語の翻訳上げるというもの。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 When Do Chagnes Induce Fixes?</title>
      <link>https://nryotaro.github.io/post/when_do_changes_induce_fixes/</link>
      <pubDate>Fri, 03 Aug 2018 21:47:03 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/when_do_changes_induce_fixes/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;ざっくり言うと、バージョン管理ツールとバグチケット管理ツールを導入しているプロジェクトにおいて、
バージョン管理ツールで追跡されている変更とバグチケット管理ツールで追跡されているバグを紐付ける手法を提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>要約 A Simple Semi-supervised Algorithm For Named Entity Recognition</title>
      <link>https://nryotaro.github.io/post/a_simple_semi_supervised_for_ner/</link>
      <pubDate>Tue, 17 Jul 2018 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/a_simple_semi_supervised_for_ner/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;CRFに入力する学習データを集めるための半教師学習の手法を提案と評価した論文。
本手法はCRFに与える学習データを集めるための手法であり、CRFのアルゴリズム自体に変更を加えることはない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>要約 Applying Conditional Random Fields to Japanese Morphological Analysis</title>
      <link>https://nryotaro.github.io/post/applying_crf_to_japanese_morph_analysis/</link>
      <pubDate>Tue, 17 Jul 2018 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/applying_crf_to_japanese_morph_analysis/</guid>
      <description>&lt;p&gt;Mecabの中の人の&lt;a href=&#34;http://chasen.naist.jp/chaki/t/2009-09-30/doc/mecab-cabocha-nlp-seminar-2009.pdf&#34;&gt;資料&lt;/a&gt;で紹介でされている、Mecabのアルゴリズムを提案・評価した論文。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Text Classification from Labeled and Unlabeled Documents using EM</title>
      <link>https://nryotaro.github.io/post/text_cls_from_lbl_and_unlbl_doc_em/</link>
      <pubDate>Sun, 08 Jul 2018 01:23:49 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/text_cls_from_lbl_and_unlbl_doc_em/</guid>
      <description>&lt;h3 id=&#34;アルゴリズム&#34;&gt;アルゴリズム&lt;/h3&gt;

&lt;p&gt;提案手法は、Naive BayesとEMアルゴリズムを組み合わせたもの。
ラベル付きデータが\(D^l\)でラベルなしデータが\(D^u\)で表されるとき、対数尤度\(\log P(D^l)P(D^u)\)を最大化する問題を解く。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>