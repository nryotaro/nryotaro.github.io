<!DOCTYPE html>
<html>
    <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    
    <title>
      
      Posts - Coda
      
		</title>

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="alternate" type="application/rss&#43;xml" href="https://nryotaro.github.io/post/index.xml">
    
    <link href="https://fonts.googleapis.com/css?family=M+PLUS+Rounded+1c" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="/assets/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/normalize.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/icons.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/screen.css" />
    
    <link href="https://fonts.googleapis.com/css?family=Bree+Serif|Lato:100,100i,300,300i,400,400i,700,700i|Source+Code+Pro:300,400,500,700" rel="stylesheet">
    

    
    <script src="https://cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
    <script type="text/javascript" src="/assets/bigfoot/dist/bigfoot.js"></script>
    <link rel="stylesheet" type="text/css" href="/assets/bigfoot/dist/bigfoot-number.css" />
    <script type="text/javascript">
        $.bigfoot();
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
    
    
</head>

    <body class="tag-template">
        <header class="main-header">
	<div class="main-header-content">
		<h1 class="blog-title">
			<a href="/">
				
           Coda
				
			</a>
		</h1>
		<h2 class="blog-description"></h2>
	</div>

	<div class="nav">
    
		
	</div>
</header>

        

<main class="content" role="main">
  

	<div class="extra-pagination">
	    

<nav class="pagination" role="navigation">
    
        <a class="newer-posts" href="/post/">&larr; Newer Posts</a>
    
    <span class="page-number">Page 2 of 5</span>
    
        <a class="older-posts" href="/post/page/3/">Older Posts &rarr;</a>
    
</nav>

	</div>
  
  <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/feature_selection_for_text_categorization_on_imbalance_data/">メモ Feature Selection for Text Categorization on Imbalanced Data</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="heading">概要</h3>
<p>表題の論文は、特徴選択において、正例に顕著な特徴から選ぶ割合を明示的に決めることで、正例と負例それぞれに顕著な特徴の割合を調整することが、不均衡な文書分類における予測性能の向上に役立つことを示した。
情報利得やオッズ比など単変量統計にもとづく特徴選択において、統計量の値によって暗黙的に決められた割合と異なる割合の場合の方が予測性能が高いことを実験的に示した。</p> &hellip; <a class="read-more" href="/post/feature_selection_for_text_categorization_on_imbalance_data/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">October 12, 2019</time>
	</footer>
</article>

  
  <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/snorkel_drybell_case_study/">メモ Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="heading">概要</h3>
<p>表題の論文では、<a href="https://www.snorkel.org">Snorkel</a>というWeak Supervisionの手法をGoogleで適用した結果の考察と評価がなされている。
Weak Supervisionは、人手よりも効率良くノイズ交じりの教師データを生成する手法である。
Snorkelは、引数にサンプルを返り値にラベルを返す複数の関数をラベルなしデータに適用し、結果から関数の精度を予測し、個々の関数よりも高い精度でデータにラベルを与える。この関数をラベリング関数という。Snorkel DryBellは、Snorkelのアルゴリズムをスケールさせるために、MapReduceに適用できるように修正されたものをさす。</p> &hellip; <a class="read-more" href="/post/snorkel_drybell_case_study/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">October 05, 2019</time>
	</footer>
</article>

  
  <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/training_complex_models_with_multi_task_weak_supervision/">メモ Training Complex Models with Multi-Task Weak Supervision</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <p>論文の表題は、ソース間の粒度や精度が揃っていることを前提とせず、<a href="https://arxiv.org/pdf/1212.0478.pdf">LohとWainwrightらの手法</a>でソースの精度を推定し、ソースのラベルよりも精度が高いラベルをデータに与えるWeak supervsionの手法である。</p> &hellip; <a class="read-more" href="/post/training_complex_models_with_multi_task_weak_supervision/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">September 28, 2019</time>
	</footer>
</article>

  
  <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/snorkel_rapid_training_data_creation_with_weak_supervision/">メモ Snorkel: Rapid Traning Data Creation with Weak Supervision</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="heading">概要</h3>
<p>表題の論文は、Weak supervisionの一種であるSnorkelを学習データの収集効率と予測性能についての既存手法や教師あり学習と比べた評価をまとめてる。</p> &hellip; <a class="read-more" href="/post/snorkel_rapid_training_data_creation_with_weak_supervision/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">September 21, 2019</time>
	</footer>
</article>

  
  <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/software_engineering_for_machine_learning/">メモ Software Engineerng for Machine Learning: A Case Study</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="heading">概要</h3>
<p>表題の論文は、マイクロソフトでのAIを応用したアプリケーションの開発についての調査結果をまとている。
著者らは、9人中の8名がMicrosoft Researchに所属し、本論文で2019年のICSEのSoftware Engineering in Practiceの分野でBest Paper Awardを受賞した。
主な貢献は、各チームにおける開発フローを9のステージに分けて解説したこと、機械学習を応用するアプリケーションやプラットフォームの開発におけるベストプラクティスを示したこと、機械学習を応用するアプリケーションの開発に固有の課題にまつわる論考の3つである。</p> &hellip; <a class="read-more" href="/post/software_engineering_for_machine_learning/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">September 14, 2019</time>
	</footer>
</article>

  
  <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/class_imbalance_redux/">メモ Class Imbalance, Redux</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <p>表題の論文は、不均衡データの特徴が二値分類の予測性能に及ぼす影響を理論づける論文である。
理論と実験を通じて、多くのケースにおいて、アンダーサンプリングによる均衡データのバギングで予測性能があがったことを示している。
バギングは、アンダーサンプリングによる偏りを抑えて予測性能を安定させるために使われる。
論文で扱うモデルは、SVMなどの学習で経験損失を最小化するモデルに限定されている。発表学会は2011年のICDMである。</p> &hellip; <a class="read-more" href="/post/class_imbalance_redux/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">September 07, 2019</time>
	</footer>
</article>

  
  <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/learning_on_border/">メモ Learning on the Border: Active Learning in Imbalanced Data Classification</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="heading">概要</h3>
<p>表題にある論文は、不均衡データの二値分類についての予測性能を能動学習で改善する手法を提案している。
着想は、学習器のマージン付近では正例と負例がよりバランスしていると仮定し、
マージン付近にあるデータを集めることで、均衡のとれたデータセットを用意することにある。
具体的には、ラベルづけしたデータでSVMをオンライン学習し、無作為に抽出されたラベルのないデータの中で最も超平面に近いデータにラベルをつける手順をマージンの中にあるデータ数が変わらなくなるまで繰り返す。</p> &hellip; <a class="read-more" href="/post/learning_on_border/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">August 31, 2019</time>
	</footer>
</article>

  
  <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/distilling_the_knowledge_in_a_neural_network/">メモ Distilling the Knowledge in a Neural Network</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="heading">概要</h3>
<p>表題にあるニューラルネットワークの蒸留についての論文を紹介する。
蒸留は、既存のモデルを使い、できるだけ予測性能を落とさずに、より小さいモデルを作るための学習手法である。
既存のモデルとして想定されているのは、複数のモデルからなるモデルや正則化された大きなモデルのように予測性能は高いが計算コストが高いものであり、
蒸留の目的は本番の運用に耐えられるデプロイ可能なモデル作ることにある。
本論文は、出力層の活性化関数に温度つきソフトマックスを使った多クラス分類のモデルを蒸留する手法を提案し、実験により手法を評価している。</p> &hellip; <a class="read-more" href="/post/distilling_the_knowledge_in_a_neural_network/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">August 24, 2019</time>
	</footer>
</article>

  
  <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/fastxml/">メモ FastXML: A Fast, Accurate and Stable Tree-classifier for eXtreme Multi-label Learning</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <p>表題にあるExtreme multi-label classificationの手法を紹介する。
Extreme multi-label classificationの目的は、大量のラベルの候補から与えられたデータに関連する複数のラベルを推定する学習器を構築することにある。
FastXMLは、弱学習器に決定木を使うアンサンブル学習であり、ノードの分割の評価関数にnDCGを採用することで、学習にかかる時間と予測精度の向上を意図している。</p> &hellip; <a class="read-more" href="/post/fastxml/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">August 24, 2019</time>
	</footer>
</article>

  
  <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/advantages_and_disadvantages_of_a_monolithic_repository/">メモ Advantages and Disadvantages of a Monolithic Repository</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="heading">概要</h3>
<p>表題は、マルチリポジトリと比べたときのモノリシックリポジトリの長所と短所の調べた論文のタイトルである。
論文は2018年のICSEでGoogleから発表された。
調査方法はGoogle社のエンジニアへのアンケートとエンジニアの行動ログの分析が採用されている。
Googleではモノリシックリポジトリが採用されており、エンジニアがこれまで経験したマルチリポジトリが比較対象となっている。</p> &hellip; <a class="read-more" href="/post/advantages_and_disadvantages_of_a_monolithic_repository/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">August 17, 2019</time>
	</footer>
</article>

  
  

<nav class="pagination" role="navigation">
    
        <a class="newer-posts" href="/post/">&larr; Newer Posts</a>
    
    <span class="page-number">Page 2 of 5</span>
    
        <a class="older-posts" href="/post/page/3/">Older Posts &rarr;</a>
    
</nav>

</main>

        <footer class="site-footer">
  <section class="rss"><a class="subscribe-button icon-feed" href="/index.xml"></a></section>
  
  
  <section>
    <a class="fas fa-rss" href="/index.xml"></a>
    <a class="fab fa-github" href="https://github.com/nryotaro"></a>
    <a class="fab fa-linkedin" href="https://www.linkedin.com/in/nakamura-ryotaro"></a>
  </section>
  <section class="copyright">&copy; 2019 Nakamura, Ryotaro</section>
</footer>



    </body>
</html>
